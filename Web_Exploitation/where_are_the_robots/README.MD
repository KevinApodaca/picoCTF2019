# Challenge
Can you find the robots? `https://2019shell1.picoctf.com/problem/32229/` ([link](https://2019shell1.picoctf.com/problem/32229/)) or `http://2019shell1.picoctf.com:32229`
---
## Solution
Here I had to search the url with the *robots.txt* extension and look for the word **Disallow**, from here this will hopefully tell us what webpage the developer does not want us to look at. So now we must go to that URL at that disallowed homepage, I do that with w3m.

After I have gotten to that webpage I then search for the flag which will hopefully be displayed as plain text. Finally I just save the flag to a txt file and just open that page in the browser. <br>

The script is bellow:
```bash
#! bin/bash
curl -ss https://2019shell1.picoctf.com/problem/32229/robots.txt > tmp.txt
grep Disallow tmp.txt | awk '{print $2}' > tmp2.txt
w3m https://2019shell1.picoctf.com/problem/32229/`cat tmp2.txt` | grep pico > flag.txt
cat flag.txt
open https://2019shell1.picoctf.com/problem/32229/`cat tmp2.txt`
rm tmp.txt tmp2.txt
```